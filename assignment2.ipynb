{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 06:54:41.550054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 06:54:42.722537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-04 06:54:42.722624: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-04 06:54:42.722632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from pprintpp import pprint\n",
    "from numpy import percentile\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from fastFM import als\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the data from the two data files\n",
    "reviews_file = open(\"reviews.txt\", \"r\")\n",
    "edges_file = open(\"edges.txt\", \"r\")\n",
    "reviews = {}\n",
    "edges = set()\n",
    "\n",
    "while True:\n",
    "    reviews_content = reviews_file.readline()\n",
    "    if not reviews_content:\n",
    "        break\n",
    "    exec(reviews_content)\n",
    "    \n",
    "while True:\n",
    "    edges_content = edges_file.readline()\n",
    "    if not edges_content:\n",
    "        break\n",
    "    edge = tuple(edges_content.split())\n",
    "    edges.add(edge)\n",
    "\n",
    "reviews_file.close()\n",
    "edges_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Data Exploration Features for Reviews\n",
    "    # Number of reviews\n",
    "    # Number of users\n",
    "    # Number of books\n",
    "    # Average of stars\n",
    "    # Number of each stars\n",
    "    # Average of nhelpful\n",
    "    # Number of missing\n",
    "    # Five number summary of stars (min, max, median, 1st quartile, 3rd quartile)\n",
    "    # Average number of reviews per individual\n",
    "    # Number of individuals with no reviews\n",
    "    # Average length of comment  \n",
    "    # Flag values\n",
    "    # Number of not_a_review reports\n",
    "    # Number of abuse reports\n",
    "\n",
    "# Important Data Exploration Features for Edges\n",
    "    # Number of connections\n",
    "    # Average number of friends\n",
    "    # Number of individuals with friends\n",
    "    # Number of individuals with no friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review Statistics Processing ##\n",
    "stars = []\n",
    "nhelpfuls = []\n",
    "comments = []\n",
    "star_vals = defaultdict(int)\n",
    "users_toBooks = defaultdict(set)\n",
    "books_toUsers = defaultdict(set)\n",
    "missing_dict = {\n",
    "    'comment': 0,\n",
    "    'flags': 0,\n",
    "    'nhelpful': 0,\n",
    "    'stars': 0,\n",
    "    'time': 0,\n",
    "    'unixtime': 0,\n",
    "    'user': 0,\n",
    "    'work': 0\n",
    "}\n",
    "flag_values = set()\n",
    "not_a_review_count = 0\n",
    "abuse_count = 0\n",
    "\n",
    "for key, review in reviews.items():\n",
    "    book_id, username = key\n",
    "    users_toBooks[username].add(book_id)\n",
    "    books_toUsers[book_id].add(username)\n",
    "\n",
    "    if \"stars\" in review:\n",
    "        stars.append(review[\"stars\"])\n",
    "        star_vals[review[\"stars\"]] += 1\n",
    "    else:\n",
    "        missing_dict[\"stars\"] += 1\n",
    "\n",
    "    if \"nhelpful\" in review:\n",
    "        nhelpfuls.append(review[\"nhelpful\"])\n",
    "    else:\n",
    "        missing_dict[\"nhelpful\"] += 1\n",
    "\n",
    "    if \"comment\" in review:\n",
    "        comments.append(review[\"comment\"])\n",
    "    else:\n",
    "       missing_dict[\"comment\"] += 1\n",
    "\n",
    "    if \"flags\" in review:\n",
    "        if len(review[\"flags\"]) > 0:\n",
    "            flag_values.update(review[\"flags\"])\n",
    "            if \"not_a_review\" in review[\"flags\"]:\n",
    "                not_a_review_count += 1\n",
    "            if \"abuse\" in review[\"flags\"]:\n",
    "                abuse_count += 1\n",
    "\n",
    "    missing_dict[\"flags\"] += 1 if \"flags\" not in review else 0\n",
    "    missing_dict[\"time\"] += 1 if \"time\" not in review else 0\n",
    "    missing_dict[\"unixtime\"] += 1 if \"unixtime\" not in review else 0\n",
    "    missing_dict[\"user\"] += 1 if \"user\" not in review else 0\n",
    "    missing_dict[\"work\"] += 1 if \"work\" not in review else 0\n",
    "\n",
    "review_len = len(reviews)\n",
    "user_len = len(users_toBooks)\n",
    "book_len = len(books_toUsers)\n",
    "star_avg = sum(stars) / len(stars)\n",
    "help_avg = sum(nhelpfuls) / len(nhelpfuls)\n",
    "stars_min = min(stars)\n",
    "stars_max = max(stars)\n",
    "stars_quarts = percentile(stars, [25, 50, 75])\n",
    "\n",
    "avg_books = 0\n",
    "for user, books in users_toBooks.items():\n",
    "    avg_books += len(books)\n",
    "avg_books /= user_len\n",
    "\n",
    "avg_users = 0\n",
    "for book, users in books_toUsers.items():\n",
    "    avg_users += len(users)\n",
    "avg_users /= book_len\n",
    "\n",
    "avg_comment = 0\n",
    "for comment in comments:\n",
    "    avg_comment += len(comment)\n",
    "avg_comment /= len(comments)\n",
    "\n",
    "str_flags = \", \".join(flag_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 1707070\n",
      "Number of users: 83195\n",
      "Number of books: 506165\n",
      "Average of stars: 3.8054164873497793\n",
      "Number of each stars:\n",
      "{\n",
      "    0.5: 7151,\n",
      "    1.0: 28721,\n",
      "    1.5: 9571,\n",
      "    2.0: 79025,\n",
      "    2.5: 37063,\n",
      "    3.0: 244615,\n",
      "    3.5: 116782,\n",
      "    4.0: 439640,\n",
      "    4.5: 85599,\n",
      "    5.0: 339042,\n",
      "}\n",
      "\n",
      "Average of nhelpful: 0.17973721054203987\n",
      "Number of missing data points:\n",
      "{\n",
      "    'comment': 0,\n",
      "    'flags': 0,\n",
      "    'nhelpful': 0,\n",
      "    'stars': 319861,\n",
      "    'time': 0,\n",
      "    'unixtime': 0,\n",
      "    'user': 0,\n",
      "    'work': 0,\n",
      "}\n",
      "\n",
      "Min star value: 0.5\n",
      "Q1 star value: 3.0\n",
      "Median star value: 4.0\n",
      "Q3 star value: 4.5\n",
      "Max star value: 5.0\n",
      "\n",
      "Average number of books per user: 20.51890137628463\n",
      "Average number of users per book: 3.3725563798366145\n",
      "Average length of comment: 793.5943446958825\n",
      "\n",
      "Flag values: not_a_review, abuse\n",
      "Number of not_a_review reports: 62395\n",
      "Number of abuse reports: 13472\n"
     ]
    }
   ],
   "source": [
    "## Review Statistics Outputting ##\n",
    "# Number of reviews\n",
    "print(\"Number of reviews:\", review_len)\n",
    "\n",
    "# Number of users\n",
    "print(\"Number of users:\", user_len)\n",
    "\n",
    "# Number of books\n",
    "print(\"Number of books:\", book_len)\n",
    "\n",
    "# Average of stars\n",
    "print(\"Average of stars:\", star_avg)\n",
    "\n",
    "# Number of each stars\n",
    "print(\"Number of each stars:\")\n",
    "pprint(dict(star_vals))\n",
    "\n",
    "# Average of nhelpful\n",
    "print(\"\\nAverage of nhelpful:\", help_avg)\n",
    "\n",
    "# Number of missing data points\n",
    "print(\"Number of missing data points:\")\n",
    "pprint(dict(missing_dict))\n",
    "\n",
    "# Five number summary of stars (min, max, median, 1st quartile, 3rd quartile)\n",
    "print(\"\\nMin star value:\", stars_min)\n",
    "print(\"Q1 star value:\", stars_quarts[0])\n",
    "print(\"Median star value:\", stars_quarts[1])\n",
    "print(\"Q3 star value:\", stars_quarts[2])\n",
    "print(\"Max star value:\", stars_max)\n",
    "\n",
    "# Average number of books per user\n",
    "print(\"\\nAverage number of books per user:\", avg_books)\n",
    "\n",
    "# Average number of users per book\n",
    "print(\"Average number of users per book:\", avg_users)\n",
    "\n",
    "# Average length of comment\n",
    "print(\"Average length of comment:\", avg_comment)\n",
    "\n",
    "# Flag values\n",
    "print(\"\\nFlag values:\", str_flags)\n",
    "\n",
    "# Number of not_a_review reports\n",
    "print(\"Number of not_a_review reports:\", not_a_review_count)\n",
    "\n",
    "# Number of abuse reports\n",
    "print(\"Number of abuse reports:\", abuse_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edges Statistics Processing ##\n",
    "edge_list = defaultdict(set)\n",
    "\n",
    "for edge in edges:\n",
    "    node1, node2 = edge\n",
    "    edge_list[node1].add(node2)\n",
    "    edge_list[node2].add(node1)\n",
    "\n",
    "edges_len = len(edges)\n",
    "\n",
    "avg_friends = 0\n",
    "for key, value in edge_list.items():\n",
    "    avg_friends += len(value)\n",
    "avg_friends /= len(edge_list)\n",
    "\n",
    "with_friends = len(edge_list)\n",
    "without_friends = user_len - with_friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connections: 202178\n",
      "Average number of friends: 4.840111606465896\n",
      "Number of individuals with friends: 65946\n",
      "Number of individuals with no friends: 17249\n"
     ]
    }
   ],
   "source": [
    "## Edges Statistics \n",
    "# Number of connetions\n",
    "print(\"Number of connections:\", edges_len)\n",
    "\n",
    "# Average number of friends (sparsity of graph)\n",
    "print(\"Average number of friends:\", avg_friends)\n",
    "\n",
    "# Number of individuals with friends\n",
    "print(\"Number of individuals with friends:\", with_friends)\n",
    "\n",
    "# Number of individuals with no friends\n",
    "print(\"Number of individuals with no friends:\", without_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allReviews = []\n",
    "for key, value in reviews.items():\n",
    "    if \"stars\" in value and len(value[\"flags\"]) == 0:\n",
    "        allReviews.append((key[1], key[0], value))\n",
    "\n",
    "train_set, test_set = train_test_split(allReviews, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stars = []\n",
    "for review in test_set:\n",
    "    test_stars.append(review[2][\"stars\"])\n",
    "\n",
    "def MSE(ypred):\n",
    "    return np.square(np.subtract(test_stars, ypred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_pred(pred):\n",
    "    truncated_pred = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] < 0.5:\n",
    "            truncated_pred.append(0.5)\n",
    "        elif pred[i] > 5:\n",
    "            truncated_pred.append(5)\n",
    "        else:\n",
    "            truncated_pred.append(pred[i])\n",
    "            \n",
    "    return truncated_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.9967558349790553\n"
     ]
    }
   ],
   "source": [
    "# Baseline always predicting total star average\n",
    "baseline_pred = [star_avg] * len(test_set)\n",
    "print(\"Baseline MSE:\", MSE(baseline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression using comment length and nhelpful MSE: 0.9953815433412995\n"
     ]
    }
   ],
   "source": [
    "# Simple linear regression based on length of comment and nhelpful\n",
    "X = [[1, len(d[2][\"comment\"]), d[2][\"nhelpful\"]] for d in train_set]\n",
    "y = [d[2][\"stars\"] for d in train_set]\n",
    "\n",
    "model = linear_model.LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_pred = [[1, len(d[2][\"comment\"]), d[2][\"nhelpful\"]] for d in test_set]\n",
    "lin_len_pred = model.predict(X_pred)\n",
    "lin_len_pred = trunc_pred(lin_len_pred)\n",
    "\n",
    "print(\"Linear Regression using comment length and nhelpful MSE:\", MSE(lin_len_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression based on bag of words\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in train_set:\n",
    "  r = ''.join([c for c in d[2][\"comment\"].lower() if not c in punctuation])\n",
    "  for w in r.split():\n",
    "    wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def word_feature(d):\n",
    "    feat = [0] * len(words)\n",
    "    r = ''.join([c for c in d['comment'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1)\n",
    "\n",
    "    return feat\n",
    "\n",
    "X = [word_feature(d[2]) for d in train_set]\n",
    "y = [d[2]['stars'] for d in train_set]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_test = [word_feature(d[2]) for d in test_set]\n",
    "bow_pred = clf.predict(X_test)\n",
    "bow_pred = trunc_pred(bow_pred)\n",
    "\n",
    "print(\"Linear Regression using bag-of-words MSE:\", MSE(bow_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity prediction MSE: 1.0098126449443923\n"
     ]
    }
   ],
   "source": [
    "# Jaccard similarity prediction model\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom\n",
    "\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerBook = defaultdict(list)\n",
    "itemAverages = {}\n",
    "ratingDict = {}\n",
    "\n",
    "for d in train_set:\n",
    "    user, item = d[0], d[1]\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    reviewsPerUser[user].append(d[2])\n",
    "    reviewsPerBook[book].append(d[2])\n",
    "    ratingDict[(user, item)] = d[2][\"stars\"]\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)\n",
    "    \n",
    "def predictRating(user, item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['work']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['stars'] - star_avg)\n",
    "        similarities.append(Jaccard(usersPerItem[item], usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x * y) for x, y in zip(ratings, similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return star_avg\n",
    "        \n",
    "sim_pred = [predictRating(d[0], d[1]) for d in test_set]\n",
    "sim_pred = trunc_pred(sim_pred)\n",
    "\n",
    "print(\"Jaccard similarity prediction MSE:\", MSE(sim_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "\n",
    "for u, i, r in allReviews:\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    interactions.append((u, i, r['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 05:33:34.314184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 05:33:34.437606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-12-04 05:33:34.437636: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-04 05:33:34.438337: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent factor model prediction MSE: 0.6323240356958874\n"
     ]
    }
   ],
   "source": [
    "# Latent factor model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(0.01)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, rbu, rbi, rgu, rgi):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)], stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)], stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs), K], stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs), K], stddev=0.001))\n",
    "        self.rbu = rbu\n",
    "        self.rbi = rbi\n",
    "        self.rgu = rgu\n",
    "        self.rgi = rgi\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.rbu * tf.reduce_sum(self.betaU**2) + self.rbi * tf.reduce_sum(self.betaI**2) + self.rgu * tf.reduce_sum(self.gammaU**2) + self.rgi * tf.reduce_sum(self.gammaI**2)\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return mse(r, pred)\n",
    "    \n",
    "def trainingStep(model, interactions):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model.call(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()\n",
    "\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "\n",
    "for u, i, r in interactions:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)\n",
    "\n",
    "modelLFM = LatentFactorModel(star_avg, 3, 0.00001, 0.00001, 0.00001, 0.00001)\n",
    "\n",
    "for i in range(500):\n",
    "    obj = trainingStep(modelLFM, interactions)\n",
    "    #if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "\n",
    "lfm_pred = [modelLFM.predict(userIDs[d[0]], itemIDs[d[1]]).numpy() for d in test_set]\n",
    "print(\"Latent factor model prediction MSE:\", MSE(lfm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using negative and positive word lists\n",
    "keys = []\n",
    "text = []\n",
    "for review in allReviews:\n",
    "    user = review[0]\n",
    "    item = review[1]\n",
    "    comment = review[2][\"comment\"]\n",
    "\n",
    "    keys.append((user, item))\n",
    "    text.append(comment)\n",
    "\n",
    "data = {'keys': keys, 'preprocess_txt': text}\n",
    "df = pd.DataFrame(data)\n",
    "df['total_len'] = df['preprocess_txt'].map(lambda x: len(x))\n",
    "\n",
    "pos_words = set()\n",
    "for l in open(\"positive-words.txt\"):\n",
    "    if l[0] == \";\": continue\n",
    "    pos_words.add(l)\n",
    "\n",
    "neg_words = set()\n",
    "for l in open(\"negative-words.txt\"):\n",
    "    if l[0] == \";\": continue\n",
    "    neg_words.add(l)\n",
    "\n",
    "num_pos = df['preprocess_txt'].map(lambda x: len([i for i in x if i in pos_words]))\n",
    "df['pos_count'] = num_pos\n",
    "\n",
    "num_neg = df['preprocess_txt'].map(lambda x: len([i for i in x if i in neg_words]))\n",
    "df['neg_count'] = num_neg\n",
    "\n",
    "df['sentiment'] = round((df['pos_count'] - df['neg_count']) / df['total_len'], 3)\n",
    "\n",
    "df = df.set_index('keys')\n",
    "df.to_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis Using NLTK\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "user_ids = []\n",
    "book_ids = []\n",
    "comments = []\n",
    "neg = []\n",
    "neu = []\n",
    "pos = []\n",
    "comp = []\n",
    "\n",
    "for review in allReviews:\n",
    "    user = review[0]\n",
    "    item = review[1]\n",
    "    comment = review[2][\"comment\"]\n",
    "\n",
    "    score = sia.polarity_scores(comment)\n",
    "\n",
    "    user_ids.append(user)\n",
    "    book_ids.append(item)\n",
    "    comments.append(comment)\n",
    "\n",
    "    neg.append(score[\"neg\"])\n",
    "    neu.append(score[\"neu\"])\n",
    "    pos.append(score[\"pos\"])\n",
    "    comp.append(score[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {}\n",
    "for i in range(len(user_ids)):\n",
    "    sentiment_dict[(user_ids[i], book_ids[i])] = comp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression using comment length, nhelpful, and sentiment analysis MSE: 0.9602633065284476\n"
     ]
    }
   ],
   "source": [
    "# Simple linear regression based on length of comment, nhelpful, and sentiment analysis\n",
    "X = [[1, len(d[2][\"comment\"]), d[2][\"nhelpful\"], sentiment_dict[(d[0], d[1])]] for d in train_set]\n",
    "y = [d[2][\"stars\"] for d in train_set]\n",
    "\n",
    "model = linear_model.LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_pred = [[1, len(d[2][\"comment\"]), d[2][\"nhelpful\"], sentiment_dict[(d[0], d[1])]] for d in test_set]\n",
    "simple_sent_pred = model.predict(X_pred)\n",
    "simple_sent_pred = trunc_pred(lin_len_pred)\n",
    "\n",
    "print(\"Linear Regression using comment length, nhelpful, and sentiment analysis MSE:\", MSE(simple_sent_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression using bag-of-words, sentiment analysis, and length of comment MSE: 0.8089379034328351\n"
     ]
    }
   ],
   "source": [
    "# Linear regression with the most features based on bag of words, sentiment analysis, and length of comment\n",
    "def word_feature(d):\n",
    "    feat = [0] * len(words)\n",
    "    r = ''.join([c for c in d[2]['comment'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "\n",
    "    feat.append(sentiment_dict[(d[0], d[1])])\n",
    "    feat.append(len(d[2]['comment']))\n",
    "    feat.append(1)\n",
    "\n",
    "    return feat\n",
    "\n",
    "X = [word_feature(d) for d in train_set]\n",
    "y = [d[2]['stars'] for d in train_set]\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_test = [word_feature(d) for d in test_set]\n",
    "lin_sent_pred = clf.predict(X_test)\n",
    "lin_sent_pred = trunc_pred(bow_pred)\n",
    "\n",
    "print(\"Linear Regression using bag-of-words, sentiment analysis, and length of comment MSE:\", MSE(lin_sent_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorization Machine with no features MSE: 1.105352281188836\n"
     ]
    }
   ],
   "source": [
    "# Factorization Machine with no features\n",
    "userIDs, itemIDs = {}, {}\n",
    "\n",
    "for d in allReviews:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "\n",
    "X = scipy.sparse.lil_matrix((len(allReviews), nUsers + nItems))\n",
    "\n",
    "for i in range(len(allReviews)):\n",
    "    user = userIDs[allReviews[i][0]]\n",
    "    item = itemIDs[allReviews[i][1]]\n",
    "    X[i, user] = 1\n",
    "    X[i, nUsers + item] = 1\n",
    "\n",
    "y = np.array([d[2]['stars'] for d in allReviews])\n",
    "X_train, y_train = X[:len(train_set)], y[:len(train_set)]\n",
    "X_test, y_test = X[len(train_set):], y[len(train_set):]\n",
    "\n",
    "fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=5, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "\n",
    "simple_fm_pred = fm.predict(X_test)\n",
    "simple_fm_pred = trunc_pred(simple_fm_pred)\n",
    "print(\"Factorization Machine with no features MSE:\", MSE(simple_fm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     X[i, user] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     X[i, nUsers \u001b[39m+\u001b[39m item] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     X[i, nUsers \u001b[39m+\u001b[39m nItems] \u001b[39m=\u001b[39m sentiment_dict[(allReviews[i][\u001b[39m0\u001b[39m], allReviews[i][\u001b[39m1\u001b[39m])]\n\u001b[1;32m     20\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([d[\u001b[39m2\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mstars\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m allReviews])\n\u001b[1;32m     21\u001b[0m X_train, y_train \u001b[39m=\u001b[39m X[:\u001b[39mlen\u001b[39m(train_set)], y[:\u001b[39mlen\u001b[39m(train_set)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Factorization Machine with an additional sentiment analysis feature\n",
    "userIDs, itemIDs = {}, {}\n",
    "\n",
    "for d in allReviews:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "\n",
    "X = scipy.sparse.lil_matrix((len(allReviews), nUsers + nItems + 1))\n",
    "\n",
    "for i in range(len(allReviews)):\n",
    "    user = userIDs[allReviews[i][0]]\n",
    "    item = itemIDs[allReviews[i][1]]\n",
    "    X[i, user] = 1\n",
    "    X[i, nUsers + item] = 1\n",
    "    X[i, nUsers + nItems] = sentiment_dict[(allReviews[i][0], allReviews[i][1])]\n",
    "\n",
    "y = np.array([d[2]['stars'] for d in allReviews])\n",
    "X_train, y_train = X[:len(train_set)], y[:len(train_set)]\n",
    "X_test, y_test = X[len(train_set):], y[len(train_set):]\n",
    "\n",
    "fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=5, l2_reg_w=0.1, l2_reg_V=0.5)\n",
    "fm.fit(X_train, y_train)\n",
    "\n",
    "simple_fm_pred = fm.predict(X_test)\n",
    "simple_fm_pred = trunc_pred(simple_fm_pred)\n",
    "print(\"Factorization Machine with an additional sentiment analysis feature MSE:\", MSE(simple_fm_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
